{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Our First day of productivity!!! Turn Uhhhhhh!!!!!!\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(corpus):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    corpus_tokenized = tokenizer.texts_to_sequences(corpus)\n",
    "    dictSize = len(tokenizer.word_index)\n",
    "    return corpus_tokenized, dictSize #Returns a list of numbers where each number corresponds to the word at that index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binary representation of vector\n",
    "def to_categorical(y, num_classes=None):\n",
    "    \"\"\"\n",
    "    y: Vec to be converted\n",
    "    \n",
    "    Returns: A binary matrix rep of the input\n",
    "    \"\"\"\n",
    "    y = np.array(y, dtype='int')\n",
    "    input_shape = y.shape\n",
    "    \n",
    "    '''\n",
    "    -input_shape must exist\n",
    "    -most basic array in y only has one element\n",
    "    -input_shape only has one dimension\n",
    "    ie.\n",
    "    tre = [[0],\n",
    "           [0],\n",
    "           [0]]\n",
    "    in this case the shape of tre is (3, 1) which means that it satisfies all three conditions\n",
    "    \n",
    "    '''\n",
    "    if input_shape and input_shape[-1] == 1 and len(input_shape) > 1:\n",
    "        input_shape = tuple(input_shape[:-1]) #Trims out the last index in the shape tuple\n",
    "        \n",
    "    y = y.ravel() #Returns a 1D array rep of y\n",
    "    if not num_classes:\n",
    "        num_classes = np.max(y) + 1\n",
    "    n = y.shape[0]\n",
    "    categorical = np.zeros((n, num_classes))\n",
    "    categorical = np.reshape(categorical, output_shape)\n",
    "    return categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus2io(corpus_tokenized, dictSize, window_size):\n",
    "    for words in corpus_tokenized:\n",
    "        L = len(words)\n",
    "        for index, word in enumerate(words):\n",
    "            labels = []\n",
    "            context = []\n",
    "            s = index - window_size\n",
    "            e = index + window_size + 1\n",
    "            context.append([words[i] - 1 for i in range(s, e) if 0 <= i < L and i != index])\n",
    "            labels.append(word - 1)\n",
    "            x = np_utils.to_categorical(context, dictSize)\n",
    "            y = np_utils.to_categorical(labels, dictSize)\n",
    "            yield(x, y.ravel())\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \n",
      " center word = \" [1. 0. 0. 0. 0. 0. 0.] \n",
      " context words =\n",
      " [[[0. 1. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 1. 0. 0. 0. 0.]]]\n",
      "1 \n",
      " center word = \" [0. 1. 0. 0. 0. 0. 0.] \n",
      " context words =\n",
      " [[[1. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 1. 0. 0. 0.]]]\n",
      "2 \n",
      " center word = \" [0. 0. 1. 0. 0. 0. 0.] \n",
      " context words =\n",
      " [[[1. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 1. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 1. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 1. 0. 0.]]]\n",
      "3 \n",
      " center word = \" [0. 0. 0. 1. 0. 0. 0.] \n",
      " context words =\n",
      " [[[0. 1. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 1. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 1. 0.]]]\n",
      "4 \n",
      " center word = \" [0. 0. 0. 0. 1. 0. 0.] \n",
      " context words =\n",
      " [[[0. 0. 1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 1. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 1. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 1.]]]\n",
      "5 \n",
      " center word = \" [0. 0. 0. 0. 0. 1. 0.] \n",
      " context words =\n",
      " [[[0. 0. 0. 1. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 1. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 1.]]]\n",
      "6 \n",
      " center word = \" [0. 0. 0. 0. 0. 0. 1.] \n",
      " context words =\n",
      " [[[0. 0. 0. 0. 1. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 1. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "windowSz = 2\n",
    "corpus = ['I like playing football with my friends']\n",
    "corpus_tokenized, dictSize = tokenize(corpus)\n",
    "for i, (x,y) in enumerate(corpus2io(corpus_tokenized, dictSize, windowSz)):\n",
    "    print(i, '\\n center word = \"', y, '\\n context words =\\n', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x/e_x.sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cbow(context, label, W1, W2, loss):\n",
    "    x = np.mean(context, axis = 0)\n",
    "    h = np.dot(W1.T, x)\n",
    "    u = np.dot(W2.T, h)\n",
    "    y_pred = softmax(u)\n",
    "    \n",
    "    e = -label + y_pred\n",
    "    dW2 = np.outer(h, e)\n",
    "    dW1 = np.outer(x, np.dot(W2, e))\n",
    "    \n",
    "    new_W1 = W1 - eta * dW1\n",
    "    new_W2 = W2 - eta * dW2\n",
    "    \n",
    "    loss += -float(u[label == 1]) + np.log(np.sum(np.exp(u)))\n",
    "    \n",
    "    return new_W1, new_W2, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
